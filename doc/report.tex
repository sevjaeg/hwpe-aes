\documentclass[a4paper, 12pt]{article}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}  % ngerman for German
\usepackage{lmodern}  % nicer font
\usepackage{geometry}
\geometry{%
	left   = 2.5cm,
	right  = 2.5cm,
	top    = 3cm,
	bottom = 3cm
}

\usepackage{textcomp}
\usepackage{gensymb}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{nicefrac}  % nicer inline fractions
\usepackage{tensor}  % allows fancy indices
\usepackage{siunitx}  % easy handling of value + unit (e.g. \SI{10}{\pF})
% \sisetup{}  % configure siunitx (e.g. locale = DE)
\sisetup{math-micro=\text{µ},text-micro=µ} % add /micro
\sisetup{output-complex-root=\ensuremath{\mathrm{j}}, complex-root-position = before-number} % configures SI format 10 + j5 for complex numbers (instead of 10 + 5i)

\usepackage{listings}  % code listings
\usepackage{verbatim}  % inline code (\verb||)
\usepackage{enumerate}
\usepackage[shortlabels]{enumitem}  % simple format for enumerations (e.g. 
\usepackage{booktabs}  % nicer tables (e.g. \toprule)
\usepackage{subcaption}  % captions for subplots
\usepackage[european, siunitx, RPvoltages]{circuitikz}  % draw circuit diagrams

\setlist[itemize]{label=\rule[0.5ex]{0.6ex}{0.6ex}} % black squares for itemize

\usepackage{pstool}  %% Tex fonts in EPS files
\usepackage{graphicx}
\graphicspath{{./figures/}}

\setlength {\marginparwidth }{2cm}  % fixes issue with todonotes
\usepackage{todonotes}
\usepackage{etoolbox} % Needed for AtBeginEnvironment command (appendix handling)
\usepackage{appendix} % Appendices environment

\usepackage{csquotes} % removes biber warning
\usepackage[  % ieee style citations (e.g. [1])
	backend     = biber,
	maxbibnames = 99,
	autocite    = footnote,
	style	    = ieee,
	citestyle   = numeric-comp,
	doi=false, isbn=false
]{biblatex}
\addbibresource{bibliography/bibliography.bib}

\usepackage[nobiblatex]{xurl}  % line breaks in URLs
% last imports
\usepackage[bookmarksopen,colorlinks,citecolor=black,linkcolor=black, urlcolor = black]{hyperref}

% after hyperref! 
\usepackage[noabbrev, nameinlink]{cleveref} 
% e.g. \cref{label} or \Cref(label) for capital letter
% configure cleveref not to use brackets around equation references
\creflabelformat{equation}{#2\textup{#1}#3} % Equation references without parentheses
\AtBeginEnvironment{appendices}{\crefalias{section}{appendix}} % Appendix referencing (for cref "Appendix A" instead of "Section A")


% add missing hyphenations
\hyphenation{im-ple-men-ta-tions}

\title{384.180 SoC Advanced Course\\
	   Integration of an Encryption Accelerator
	   into an Open-Source Low-Power Microcontroller}
\author{
  Severin Jäger, 01613004
}
\date{\today}


\begin{document}

\maketitle
\tableofcontents
\pagebreak

\section{Introduction} \label{sec:intro}

Extreme edge devices are increasingly expected to perform signal processing workloads. Sensor signals are frequently processed directly in the sensor node before being transmitted for further analysis. Examples include simple machine learning algorithms detecting relevant sequences or events in a sensor signal. However, such edge devices are usually battery-powered and optimised for long battery lifetimes. Thus, the energy consumption is highly constrained. Therefore, applications have to be designed with energy efficiency in mind. This is also a main factor when partitioning between hardware and software.

One major academic project focussing on energy-efficient processor and system design is the PULP platform~\cite{pulp} by ETH Zurich and University of Bologna. Over the last years, the PULP team has developed several processor cores as well as peripherals and full systems on chips (SoCs). Utilising the open source instruction set architecture RISC-V, the RTL code of the IP cores developed within this project is available publicly with a permissive license.

In certain applications including biomedical devices, video surveillance, or home automation, the aforementioned requirements are complemented by a need for confidentiality. Thus, standard cryptographic algorithms have to be executed on the edge hardware. Unfortunately, processing these algorithms in software is relatively complex and consumes significant memory, time, and therefore energy. These issues might however be alleviated by offloading the computation to a dedicated cryptographic accelerator. The scope of this project is integrating and open-source hardware accelerator into the PULPissimo SoC~\cite{Schiavone2018} and comparing it to a reference software implementation. Additionally, an FPGA demonstration, a partial ASIC synthesis flow, and power estimations are part of this project.

\section{Background} \label{sec:background}

\subsection{PULPissimo}

PULPissimo is a microcontroller and as such one of the smaller platforms within the PULP ecosystem. It comes with a single RISC-V core, tightly-coupled data memory (TCDM, in essence an L2 cache), a DMA controller, and a full set of peripherals controlled via a bus. Furthermore, it allows the convenient integration of a so-called hardware processing engine (HWPE) which directly operates on the TCDM. The SoC architecture is depicted in \Cref{pulpissimo-arch}.

\begin{figure}
	\centering
	\includegraphics[width=0.6\textwidth]{pulpissimo_arch.png}
	\caption{Architecture of the PULPissimo SoC \cite{pulpissimo}}
	\label{pulpissimo-arch}
\end{figure}

The design is mainly targeting ASIC technology and focussed on maximising energy efficiency. In a \SI{22}{nm} FD-SOI technology, an energy efficiency of \SI{433}{MOPS/mW} has been shown~\cite{Schiavone2018}. The full SystemVerilog RTL code including scripts for simulation and FPGA evaluation is available on GitHub~\cite{pulpissimo}.

\subsubsection*{Hardware Processing Engine (HWPE)}

The PULP hardware processing engine is a quite unique hardware accelerator. As depicted in \Cref{hwpe-arch}, it consists of a data interface, a control interface and the data path. In contrast to most accelerators in literature it neither uses a dedicated accelerator interface in the CPU nor direct memory access (DMA) to get the data to the processing units. Instead, it shares the tightly-coupled data memory with the processor core. The control interface is connected to the peripheral bus and is thus seen as a memory-mapped peripheral by the CPU. It provides configuration registers which can be read and written by the processor.

\begin{figure}
	\centering
	\includegraphics[width=0.65\textwidth]{hwpe.png}
	\caption{Architecture of a PULP Hardware Processing Engine \cite{hwpe}}
	\label{hwpe-arch}
\end{figure}

A typical HWPE operation works as follows. Firstly, the relevant data has to be placed in the shared memory (TCDM). Then, the CPU sets all relevant configuration data (e.g. pointers of source and destination in shared memory, data size, HWPE configuration) via the HWPE´s control interface. Once a HWPE operation is started, it operates fully autonomous and the CPU can perform other computations. After completion, the HWPE triggers an event which can be polled in the CPU or raise an interrupt. The event indicates that the output data is written to the shared memory.

HWPEs are not limited to PULPissimo, but can also be integrated into more powerful SoCs within the PULP project including multicore systems and HPC clusters. Thus, the effort of designing an HWPE can be reused easily. Furthermore, a template HWPE implementing a multiply-accumulate (MAC) engine is available~\cite{hwpe-mac}. This template features a relatively simple data path, but a powerful control interface including a microcode processor and a finite state machine as well as three 32-bit inputs and one 32-bit output. The template is intended as starting point for new HWPEs and alleviates the burden for the developer to implement a device driver and to handle the memory access. The work in this project is based on this template.

\subsection{AES Hardware}

The advanced encryption standard (AES) defines a set of block-cipher algorithms which are also known under their original Dutch name Rijndael. It works on 128-bit data words and uses either 128, 192, or 256-bit keys. The algorithm was designed for straightforward hardware implementation and is one of the most frequently used block ciphers.

In general, AES operates in (mostly) identical rounds (10 for 128-bit keys), each of which consists of different mathematical steps. Hardware designs might implement these operations once and compute the round results sequentially or pipeline them to some extent. Faster implementations consist of several parallel round hardware blocks.

Thus, several hardware implementation of the AES algorithms are available. As this project uses open-source SystemVerilog RTL code, only permissively-licensed open-source (System)Verilog implementations were considered. \Cref{tab:aes_cores} compares the three most relevant IP cores. An edge device requires only encryption capabilities to transfer sensor data in a secure way. Due to size and energy limitations, only AES with 128-bit keys was considered.

\begin{table}[h]
    \centering
    \begin{tabular}{c|c c c}
        \toprule
        IP Core &  \verb|tiny_aes|~\cite{tiny-aes} & \verb|aes_128|~\cite{aes-128} & \verb|secworks_aes|~\cite{secworks-aes}  \\
        \midrule
        Cycles/op &  1 & 12 & 4\\
        Latency (cylces) & 21 & 12 & 14\\
        LUTs & 4588 & 487 & 3327 \\
        Registers & 4474 & 402 & 2990 \\
        BRAM tiles & 68 & 5 & 0 \\
        Max. frequency [MHz] & 375.9 & 180.5 & 124.8 \\
        Decryption & no & yes  & yes \\
        256-bit keys & no & no & yes\\
        \bottomrule
    \end{tabular}
	\caption{Comparison of selected open-source AES IP cores. Resource consumption and clock frequency were obtained with Vivado 2020.2 synthesising for a Nexys~4~DDR evaluation board.}
	\label{tab:aes_cores}
\end{table}

Clearly, the \verb|tiny_aes| core provides the best performance. It is fully pipelined and thus offes the highest throughput and the shortest critical path. In contrast, \verb|aes_128| is a minimalistic implementation that reuses the stages of the AES algorithm to minimise hardware resources. In between, the \verb|secworks_aes| core finds a trade-off and optionally offers features that are not required for this project (decryption and larger keys). Given the energy constraints and the most likely relatively low number of transmissions required, the \verb|aes_128| IP core was selected to be integrated into PULPissimo as HWPE.

\section{Baseline Implementation} \label{sec:implementation}

A first step towards integrating the \verb|aes_128| core into PULPissimo was already taken in a prior course. This report mainly focusses on the new contributions. Still, a wrap-up of the prior work is given in this section for easier understanding.

\subsection{Setup} \label{sec:implementation:setup}

As PULPissimo is written in SystemVerilog and the scripts require either Mentor Questa Sim or Cadence Xcelium, an ICT EDA server was used to run the Mentor toolchain. This required working on the server´s file system and mounting the relevant directories via \texttt{sshfs} on the local machine as all required dependencies for compilation were installed there. As the PULPissimo scripts make use of environment variables frequently, doing so required several scripts enabling a seamless workflow when switching back and forth between the two platforms.

\subsection{Reference Software}

To have a reasonable baseline, a software implementation of the AES algorithm was required. Due to its small code size which perfectly fits microcontroller environments, the Tiny AES in C~\cite{tiny-aes-c} implementation was chosen. It easily compiles for PULPissimo with the PULP SDK and requires only around \SI{2}{kiB} of memory. The software library offers several encryption modes and key sizes. However, for the first version only electronic code book (ECB) encryption capability with 128 bit keys was used. 

\subsection{Hardware Processing Engine}

The design of the AES HWPE supports only 128-bit ECB encryption and is based on the PULP MAC engine template~\cite{hwpe-mac}. It contains the AES IP core as well as units converting the 32-bit memory words to 128-bit AES keys and words (word\_stackers and word\_unstacker). The resulting AES HWPE architecture is depicted in \Cref{hwpe-aes}. The input and output streamers are controlled by the FSM in the control block which uses the registers written by the CPU beforehand. All data path units use a simple ready/valid handshake to allow both forward and backward dependencies, e.g. if the AES unit is busy of no new data is provided by the input streamers yet.

\begin{figure} [h]
	\centering
	\includegraphics[width=0.95\textwidth]{hwpe_aes.pdf}
	\caption{Block diagram of the implemented AES HWPE}
	\label{hwpe-aes}
\end{figure}

\section{Improved AES Engine} \label{sec:improvements}

The work described from here on was conducted during the SoC Advanced course. Firstly, the AES engine has been improved and demonstrated on an FPGA. Additionally, an ASIC implementation flow was performed. The corresponding results of the latter are described in \Cref{sec:asic}.

\subsection{Register Reduction}

In a first step, the pipelining registers depicted in \Cref{hwpe-aes} were removed. They added area as well as increased the latency without providing any value to the timing behaviour as both the byte\_stacker modules and the AES IP core already provide pipelining registers at their outputs.

\subsection{Cipher Block Chaining}

As the electronic code book encryption mode produces identical output values for identical input blocks, it lacks the so-called diffusion property and is thus not considered safe. Therefore, the AES core was extended to support the cipher block chaining (CBC) mode of operation. Here, the plain text is XOR-connected with the last ciphertext to produce different outputs for identical inputs, s. \Cref{fig:cbc}.

\begin{figure} [h]
	\centering
	\includegraphics[width=0.65\textwidth]{cbc.png}
	\caption{Cipher block chaining mode of operation \cite{wiki_cbc}}
	\label{fig:cbc}
\end{figure}

Adding CBC support to the AES HWPE requires only small modifications. Firstly, a register storing the last ciphertext is required. Then, a 128-bit XOR block has to be added. The resulting architecture is shown in \Cref{hwpe-aes-update}. As the pipeline features a ready-valid handshake system which is not depicted, some additional handshake signals are required to ensure that each ciphertext is used exactly once. The reset value of the ciphertext register is the initialisation vector (IV), which is hardwired in the current implementation. In principle, it is possible to make the IV configurable via the peripheral bus interface. A further conceivable improvement is a configuration bit that allows switching between ECB and CBC.

\begin{figure} [h]
	\centering
	\includegraphics[width=0.95\textwidth]{hwpe_aes_update.pdf}
	\caption{Block diagram of the improved AES HWPE}
	\label{hwpe-aes-update}
\end{figure}

The used reference software implementation \cite{tiny-aes-c} already provides build-in CBC support and thus only a preprocessor flag has to be set. Again, a short self-checking demo application was written both for the PULPissimo CPU using the library and the HWPE. Both use the same set of data from the NIST examples~\cite{NIST}. To make sure the cipher feedback is done correctly, blocks of four encryptions are executed as the output data does not differ between ECB and CBC for a single encryption. In a first step, the HPWE was evaluated in a RTL simulation where both the reference program and the HWPE application yielded the expected results.

\subsection{Control Debugging} \label{sec:improvements:control}

Unfortunately, the HWPE did with default control logic did not work on the selected FPGA platform. During ASIC verification (s. \Cref{sec:asic:verification}), a previously-known issue \cite{pulpissimo-issue} was discovered. The original control allowed flexible pointers for the input and output data of the HWPE. However, after synthesis, the control logic produced incorrect addresses. 

As a solution, the addresses were hardwired in the accelerator. Of course, this imposes limitations on feasible computations as the input data size is now limited by the distance of the data start addresses. On the other hand, this saves several registers and simplifies the address calculation logic in the control pane and reduces the code size slightly. Ultimately, the AES HWPE has (besides control and status bits) only one configurable parameter: The input data size (which is assumed equal for key and data words).

\subsection{FPGA Demonstration}

An important part of this project was evaluating the AES HWPE on an FPGA target as FPGA synthesis was not achieved during the prior course. Initially, the selected target was the Digilent Nexys~4~DDR board which is supported by the scripts in the PULPissimo repository. However, the design fills the board almost entirely (s. \Cref{sec:improvements:results}) which makes placement and routing times extremely long. Furthermore, an external JTAG debugger is required to run code on the SoC as the built-in JTAG interface is not supported. Therefore, the Digilent Genesys~2 evaluation board was selected as it features a significantly larger Xilinx FPGA from the same generation and the provided synthesis scripts support its on-board JTAG unit.

As outlined in \Cref{sec:implementation:setup}, a mounted file system was used to work both on the institute's EDA server and a local machine. This however caused problems with Vivado 2020.2 which apparently has issues when running synthesis on mounted files. Thus, a local copy of the files was made to execute FPGA synthesis. Additionally, the FPGA designs use a different top-level file than the simulation model, thus the \verb|ENABLE_HWPE| parameter has to be set again.

Executing an application with PULPissimo on an FPGA requires a debugging session consisting of a debugger (in this case \texttt{gdb}) and an OpenOCD server providing an interface to the on-board JTAG unit. Then, the executable can be flashed onto the FPGA and the output can be observed via UART. Again, the software implementation worked flawlessly. 

\subsection{Results} \label{sec:improvements:results}

\subsubsection{Performance} \label{sec:improvements:results:performance}

Both the reference software implementation and the HPWE program were simulated and the runtimes recorded. All outputs checks passed. As the runtimes for the hardware implementation were hardly measurable from the software, they have been extraced from the waveforms. \Cref{tab:results} compares the software implementation and the HWPE. Clearly, the hardware implementation outperforms the software -- which can not make use of any hardware-accelerated encryption primitives in terms of runtime. The code size decreases for the hardware implementation as the AES functionality (including relatively large look-up tables) is offloaded to hardware. Note that the code size given here is for the full demo program and thus includes not only the AES encryption but also the stimuli and several system routines.

\begin{table}[h]
    \centering
    \begin{tabular}{c|c c}
        \toprule
        & Software & HWPE \\
        \midrule
		Cycles four encryptions & 18300 & 97 \\
		Cycles additional encryption & 4500 & 17 \\
		Relative speed-up & 1  & 264.7 \\
		Code size [bytes] & 10052 & 9096 \\
        \bottomrule
    \end{tabular}
	\caption{RTL Simulation results for different AES CBC implementations.}
	\label{tab:results}
\end{table}

The overhead for the first four encryptions relative to each further (contiguous) operation lies in the control flow. Firstly, a HWPE lock has to be acquired and both the data length and the start bit have to be set (14 cycles). Then, the streamer has to fetch the data from the TCDM (7 cycles). In a next step, the AES engine produces output data and provides them to the streamer (21 cycles). Further data words benefit from pipelining as reading in and writing out can happen simultaneously. Thus, they only take 17 cycles each (if the data is already provided in the TCDM and no memory congestion occurs). Finally, the data is transferred to the memory and the completion event is issued (4 cycles). 

\subsubsection{FPGA Resources}

\Cref{tab:results-genesys} summarises the resource consumption of different entities after synthesis for this target. Clearly, there is still plenty of headroom on the board -- this simplifies placement and routing. The HWPE introduces an overhead of \SI{7.1}{\percent} for LUTs and \SI{7.4}{\percent} for registers respectively. However, the main contributor is not the data path (HWPE engine) but the HWPE streamer which provides the interface to the tighlty-coupled data memory.

\begin{table}[h]
    \centering
    \begin{tabular}{l|r r r}
        \toprule
        Entity &  Look-up-tables & Registers & BRAM tiles \\
        \midrule
		FPGA &  203800 &  407600 &  445 \\
		\hspace{2mm}PULPissimo & 58656 & 45155 & 144 \\ 
		\hspace{4mm}HWPE Top & 3892 & 3115 & 0 \\ 
		\hspace{6mm}HWPE Ctrl & 172 & 165 & 0 \\ 
		\hspace{6mm}HWPE Streamer & 2151 & 1886 & 0 \\ 
		\hspace{6mm}HWPE Engine & 1569 & 1064 & 0 \\ 
		\hspace{8mm}AES Core & 1247 & 530 & 0 \\ 
		\hspace{8mm}Word Stacker (each) & 26 & 131 & 0 \\ 
		\hspace{8mm}Word Unstacker & 118 & 131 & 0 \\
        \bottomrule
    \end{tabular}
	\caption{Resource consumption of the PULPissimo SoC when synthesised for the Genesys~2 evaluation board.}
	\label{tab:results-genesys}
\end{table}

\pagebreak
\section{ASIC Synthesis} \label{sec:asic}

As the PULP platform is mainly concerned with energy efficiency, the designs are aimed at low-power ASIC technologies (while FPGA is limited to prototyping and demonstration). Therefore, it is interesting to perform ASIC synthesis of the AES engine to obtain comparable area and power figures.

ASIC implementation is only briefly touched in the TU Wien Embedded Systems curriculum. Therefore, a major part of the project was getting familiar with the required technologies and tools. Due to their widespread use and availability at the ICT, the Cadence toolchain and the TSMC \SI{65}{nm} technology were used. Further details are discussed in \Cref{sec:asic:tools}.

As the PULPissimo SoC has been taped out several times~\cite{pulp-chips}, the implementation is limited to the AES HWPE. The corresponding flow is outlined in the rest of this section. However, as discussed in \Cref{sec:improvements:control,sec:asic:verification}, the ASIC verification showed some issues in the design which required small design changes which unfortunately limit the design versatility.

\subsection{Technology and Tooling} \label{sec:asic:tools}

The backend design flow used for this project is based on the Cadence digital implementation toolchain and depicted in \Cref{fig:asic-flow}. Most steps are automated with \texttt{tcl} scripts and \texttt{Makefiles}. After simulation-based RTL verification, the design is synthesised to the technology-specific cells with Genus. The resulting netlist is verified both by simulation and model checking. Then, a layout is generated with Innovus. The final delay-annotated netlist is again verified and can be used for both power estimation with Voltus and static timing analysis (STA) with Tempus.

The design was implemented with TSMC \SI{65}{nm} digital standard cells featuring a cell height of 10 tracks and 6 metallisation layers. To cope with process, voltage, and temperature (PVT) variations, all analyses were conducted for three corners, namely typical (\SI{1.0}{V}, \SI{25}{\degreeCelsius}, normal transistors), best case (\SI{1.1}{V}, \SI{0}{\degreeCelsius}, fast transistors), and worst case (\SI{0.9}{V}, \SI{125}{\degreeCelsius}, slow transistors).

Despite the intention of creating an energy-efficient accelerator, hardly any power management techniques were implemented. Namely, the design neither features clock or power gating nor low-power standard cells. Furthermore, no design-for-test strategies like scan chains were used. This is due to the limited scope of this project. Of course, any silicon implementation of this design should consider making use of those industry-standard techniques.

\begin{figure} [h]
	\centering
	\includegraphics[width=0.86\textwidth]{design-flow.pdf}
	\caption{ASIC design flow used for this project}
	\label{fig:asic-flow}
\end{figure}

\clearpage

\subsection{Synthesis} \label{sec:asic:synthesis}

Before the actual synthesis can take place, the design requires appropriate timing constraints. The clock frequency was iteratively set to \SI{625}{MHz}. Higher frequencies are hardly achievable with the given RTL model. The remaining clock constraints (skew, latency, transition time) were also reduced as far as reasonably feasible. As the reset of the HWPE is asynchronous, all timing arcs starting from this signal are constrained als false paths. Notably the latches in the HWPE control pane do not require false paths as Tempus can calculate timing analyses for latch-based designs.

As the AES HWPE is no self-containing chip but intended to be integrated into a PULPissimo SoC, the input and output pins are assumed to be connected with relatively short connections to other parts of the chip. Therefore, the corresponding delay, driver, and load constraints were inspired by the behaviour of the buffers available in the cell library.

The Genus synthesis flow replaces the RTL model with generic cells, then finds suitable technology-specific cells and finally optimises the resulting netlist for area and timing. As the top-level module is specified in SystemVerilog and netlists are usually defined in Verilog, a SystemVerilog wrapper is required to instantiate the AES HWPE in a verification environment. The module parameters are tied during synthesis, thus the synthesised module has to be instantiated without any parameters.

\subsection{Implementation} \label{sec:asic:impl}

\subsubsection{Floorplanning and Placement}

As the AES HWPE is designed to be part of a PULPissimo SoC, the layout is not subject to external placement constraints and no I/O pads or ESD protection cells are required. Therefore, the floorplan creation is quite free. For the sake of simplicity, a quadratic layout was chosen. To ensure good routability, the cell density was set to \SI{75}{\percent}. This lead to a quadratic floorplan of roughly $\SI{300}{\micro m} \times \SI{300}{\micro m}$. Furthermore, a margin of \SI{5.2}{\micro m} was left for power rings. Due to a lack of external constraints, pin placement was left to the tool. Only the pin layers were constrained to the metal layers \numrange{2}{4} to avoid issues with the metal rings on layers $5$ and $6$.

In a next step, a power grid was constructed. In consist of power rings and stripes for both $V_{DD}$ and $V_{SS}$ on the top metal layers (M5 and M6). Rings and stripes have a width of \SI{2}{\micro m} each and a spacing of \SI{1}{\micro m} to comply with the design rules. Four stripes were placed both horizontally and vertically.

After placing the standard cells, the power network was routed. To avoid issues around the power grid metal, jogging\footnote{Routing orthogonal to a layer's default routing direction} was enabled.

\subsubsection{Clock Tree Synthesis, Routing and Timing Optimisation}

The clock tree was automatically generated from the timing constraints discussed in \Cref{sec:asic:synthesis}. During this process, the constraints were modified iteratively until a suitable clock tree was generated with a target transition time of \SI{80}{ps}, a latency of \SI{200}{ps}, and a skew of \SI{40}{ps}.

After an optimisation step, the design was routed. During this process, both timing and crosstalk were considered by Innovus to obtain the best results. After routing, a timing optimisation step was conducted to mitigate both setup and hold violations.

\subsubsection{Signoff Checks and Fixes} \label{sec:asic:impl:signoff}

Despite the previous timing optimisation step, some hold violations remained. This could have been fixed by introducing additional timing constraints, however in this project additional buffers were added manually. The violations occurred at the TCDM inputs and at the peripheral bus interface. As these are low-fanout nets, additional buffers were introduced easily with the Innovus ECO capabilites.

After layouting the design and closing the timing, several design rule violations remained. Firstly, the chosen cell density of \SI{75}{\percent} simplified placement and routing, however several cell density violations remained. This was corrected by adding filler cells. To avoid issues with too high densities, the design was filled up to roughly \SI{93.5}{\percent}. Then, the routing had to be fixed to mitigate design rule violations introduced while adding the fillers. In a next step, metal fill was added to comply with the corresponding rules. This was necessary on the metal layers \numrange{4}{6} and done in a timing-aware fashion not to introduce capacitances which negatively affect the timing.

Eventually, the design was placed, routed, timing-closed and the following checks passed:

\begin{itemize}
	\item Design rule check (DRC),
	\item Connectivity check, 
	\item Metal density check, and
	\item Static timing analysis (STA).
\end{itemize}

Further signoff checks including electrical rule check (ERC) and layout-versus-schematic (LVS) were not part of this project as they are not supported by the digital implementation tool.

\subsection{Verification and Power Estimation} \label{sec:asic:verification}

To make sure the design does not only comply to the foundry's design rules but also behaves correctly, both simulation-based and formal verification of the post-synthesis and post-layout netlists was conducted.

Both the post-synthesis and the post-layout netlist were (with the help of a SystemVerilog wrapper) embedded into the PULPissimo simulation platform and the demo program discussed in \Cref{sec:improvements:results} was executed correctly. The post-synthesis netlist was additionally annotated with the extracted delays. However, the simulation was conducted with a frequency of \SI{50}{MHz}. Thus, the results can not be interpreted in the light of dynamic timing analysis.

The post-layout simulation was also used to estimate the power consumption of the AES HWPE. After saving a VCD file including the signal changes in all HWPE nodes, a vector-based power analysis was run with Cadence Voltus. Due to the differing simulator clock frequency, the exact power consumption could only be projected. For validation, a second power analysis was conducted based on the switching activity of a second test bench simulating only the HWPE data path with the correct clock frequncy.

As the simulation environment is limited to a small number of test vectors, verification was also conducted by the means of logic equivalence checking. Thereto, checker scripts were generated with Genus and Innovus. After synthesis, the netlist was compared with the RTL model and after layout the final netlist was checked against the post-synthesis netlist. The checking was performed with the Cadence Conformal LEC tool.

\subsection{Results} \label{sec:asic:results}

\Cref{fig:layout} shows the generated layout. The control logic is relatively small and features several pins for the peripheral interface. The AES engine itself consumes more than half of the area, but does not have any external pins. Note that the pins on the left side are dangling as they were optimised away during synthesis. The streamer is quite large as it features FIFOs to buffer the data coming from and going to the TCDM. The vast majority of pins is connected to this part of the design. A significant share of the cells does not belong to any of the three entities. Those are the physical cells which include filler cells and the buffers of the clock tree. \Cref{tab:results-area} provides detailed area figures.

\begin{figure} [h]
	\centering
	\includegraphics[width=0.6\textwidth]{layout.png}
	\caption{Final layout with the AES engine in blue, the streamer in green, and the control pane in yellow. The pins along the left edge are dangling and therefore not connected to the HWPE internally.}
	\label{fig:layout}
\end{figure} 

\begin{table}[h]
    \centering
    \begin{tabular}{l|r r r r}
        \toprule
        Entity &  Synthesis & Layout comb. & Layout seq. & Layout total \\
        \midrule
		Floorplan &  &  & & 88863.6 \\ 
		\hspace{2mm}HWPE Top & 66642.0 & 42858.0  & 26562.8 & 69420.8 \\ 
		\hspace{4mm}HWPE Ctrl & 2559.2 & 1606.4 & 1525.6 & 3132.0  \\ 
		\hspace{4mm}HWPE Streamer & 27162.0 & 13696.0 & 14834.8 & 28530.8 \\ 
		\hspace{4mm}HWPE Engine & 36920.8 & 26820.4 & 10202.4 & 37022.8 \\ 
		\hspace{6mm}AES Core & 29442.0 & 24318.0 & 5083.2 & 29401.2 \\ 
		\hspace{6mm}Word Stacker Key & 1622.8 & 470.8  & 1152.8 & 1623.6 \\ 
		\hspace{6mm}Word Stacker Data & 1622.8 & 502.4 & 1152.8 & 1655.2 \\ 
		\hspace{6mm}Word Unstacker & 1853.2 & 701.2 & 1152.8 & 1854.0 \\
		\hspace{2mm}Physical Cells &  &  & & 19442.8 \\ 
		\hspace{4mm}Filler Cells &  &  & & 13635.2 \\ 
		\hspace{4mm}Clock Tree &  &  & & 339.2\\ 
        \bottomrule
    \end{tabular}
	\caption{Area (in $\textrm{\micro m}^2$) of the AES HWPE after synthesis and implementation}
	\label{tab:results-area}
\end{table}

As depicted in \Cref{fig:clock-tree}, the clock tree does not span over the whole HWPE. Instead, notable parts of the AES engine are unclocked. The engine consists of several AES round units which are purely combinational logic. They are placed around the pipeline registers and the word (un-)stackers and therefore greatly simplify the clock tree synthesis. In contrast, the streamer and the control logic require clocking even at the edge of the floorplan as the TCDM and peripheral bus interfaces directly go into registers and FIFOs.

\begin{figure} [h!]
	\centering
	\includegraphics[width=0.6\textwidth]{clock_tree.png}
	\caption{Synthesised clock tree of the AES HWPE. The blue blocks are the buffers.}
	\label{fig:clock-tree}
\end{figure}

The timing of the AES HWPE at a clock frequency of \SI{625}{MHz} is -- as indicated by \Cref{tab:results-timing} -- quite tight. The setup times are bounded by the latches in the register file of the control unit. As latches are not synchronous, they can borrow time from a neighbouring timing path given proper timing of the enable signal. This is heavily utilises here. The worst hold paths are in contrast related to some of the inputs as discussed in \Cref{sec:asic:impl:signoff}.

\begin{table}[h]
    \centering
    \begin{tabular}{l|c c c}
        \toprule
         & Corner &  Slack synthesis & Slack layout \\
        \midrule
		Setup & TSMC65G\_av\_slow & \SI{0}{ns} & \SI{0}{ns} \\ 
		Hold & TSMC65G\_av\_fast & - & \SI{0.001}{ns} \\ 
        \bottomrule
    \end{tabular}
	\caption{Timing slack (in $\textrm{ns}$) of the AES HWPE after synthesis and implementation}
	\label{tab:results-timing}
\end{table}

The power estimation has been conducted tree times: Once with the RTL simulation model of PULPissimo and twice with a test bench for the AES engine only. For PULPissimo, the demo program was run and in the latter case, a singly encryption and a pipelined run of 1024 encryption were tested. The results are summarised in \Cref{tab:results-power}.

\begin{table}[h]
    \centering
    \begin{tabular}{l|c c c}
        \toprule
        Test case & Engine single &  Engine pipeline & AES HWPE \\
        \midrule
		Clock frequency [MHz] & 625 & 625 & 50 \\
		Runtime $\Delta t$ [ns] & 33.6 & 27859 & 1920 \\
		AES encryptions $n_{ops}$ [mW] & 1 & 1024 & 4 \\	
		Average power $P_{avg}$ [mW] & 15.521 & 17.989 & 2.757 \\
		Static power $P_{static}$ [mW] & 0.257 & 0.28 & 0.435 \\
		Register power [mW] & 7.668 (\SI{49.4}{\percent}) & 8.39 (\SI{46.6}{\percent}) & 1.607 (\SI{58.3}{\percent}) \\
		Clock tree power [mW] & 1.499 (\SI{9.7}{\percent}) & 1.499 (\SI{8.3}{\percent}) & 0.324 (\SI{11.7}{\percent}) \\	
		Energy/op $E_{op}$ (\SI{50}{MHz}) [pJ] & - & - & 1324 \\	
		Energy/op $E_{op}$ (\SI{625}{MHz}) [pJ] & 521 & 489 & 1131 \\
        \bottomrule
    \end{tabular}
	\caption{Power profiling results. Note that the measurement period per encryption is shorter for the engine-only cases as the memory and peripheral bus transactions are not simulated for this subcircuit.}
	\label{tab:results-power}
\end{table}

The energy per operation has been calculated as

\begin{equation*}
	E_{op} = \frac{P_{avg}\,\Delta t}{n_{ops}}.
\end{equation*}

The following equation was used to project from the test bench running at \SI{50}{MHz} to the nominal frequency of the AES HWPE:

\begin{equation*}
	P_{avg,\,\SI{625}{MHz}} = \frac{625}{50} \left(P_{avg,\,\SI{50}{MHz}} - P_{static} \right) + P_{static}.
\end{equation*}

This assumes a constant static power consumption and a dynamic power linearly proportional to the clock frequency. This is a simple model, still the results are useful to have a rough understanding of the HPWE's power consumption. The engine consumes around \SI{500}{pJ} per operation out of the $~\SI{1100}{pJ}$ projection for the HWPE. This roughly matches the area share of the engine. Furthermore, the engine's power consumption is fairly split between combinational logic and registers while the overall system is dominated by sequential power consumption. This matches the area distribution between logic and registers (s. \Cref{tab:results-area}). Therefore, the projection can be used for rough power estimation.

Clearly, the energy consumed per encryption slightly declines with the number of consecutive encryptions. This is likely due to the shorter runtime due to the pipelining of encryptions and memory operations as discussed in \Cref{sec:improvements:results:performance}.

But when does offloading the encryptions to the HWPE pay off in terms of energy? Executing a RISC-V instruction on a low-power microcontroller SoC consumes \SI{3.3}{pJ}~\cite{Schiavone2018}, \SI{10.2}{pJ}~\cite{Ickes2011}, or \SI{28.5}{pJ}~\cite{Pullini2018}. Note that all these designs are implemented in low-power technology nodes use low operating voltages to minimise their energy consumption. Still, a $4\times\SI{128}{bit}$ AES computation in software takes $18300$ clock cycles cycles (s. \Cref{sec:improvements:results:performance}). Assuming one instruction per clock cycle ($\textrm{IPC}=1$), this yields an energy consumption of \SI{186.7}{nJ} (for the controller presented in~\cite{Ickes2011}). In comparison, the same operation takes \SI{4.5}{nJ} on the AES HWPE.

Of course, no processor will continuously compute encryptions. Thus, the HWPE's static power consumption while idling has to be considered as well. Assuming a clock frequency of \SI{625}{MHz} and an IPC of $1$, the AES HWPE consumes \SI{0.7}{pJ} of static energy per CPU instruction. If the CPU schedules a $4\times\SI{128}{bit}$ AES encryption after $n_{comp}$ cycles, the break even point w.r.t. to energy can be computed as

\begin{equation*}
	E_{cpu} \left(n_{comp} + n_{aes\,cpu} \right) = E_{cpu} \left(n_{comp} + n_{aes\,hwpe} \right) + E_{aes\,hwpe} + E_{static\, hwpe} n_{comp}.
\end{equation*}

Note that all energies are meant as energy per operation, and $n$ denotes numbers of RISC-V CPU instructions. The equation implies clock gating, as the dynamic power consumption of the HWPE is zero while idling. The following numbers have been obtained:

\begin{itemize}
	\item $E_{CPU} = \SI{10.2}{pJ}$, 
	\item $E_{static\, hwpe} = \SI{0.7}{pJ}$,
	\item $E_{aes\,hwpe} = \SI{4524}{pJ}$,
	\item $n_{aes\,cpu} = 18300$,
	\item $n_{aes\,hwpe} = 97$.
\end{itemize}

Solving the equation for $n_{comp}$ yields \num{259000}. Thus, offloading computations to the AES HWPE pays off if \SI{512}{bits} of data have to be encrypted every \num{259000} CPU instructions. For a clock frequency of \SI{625}{MHz}, this corresponds to a data rate of \SI{1.24}{Mbps} which corresponds to an (uncompressed) $480 \times 360$ pixels RGB image every $3.36$ seconds.

As mentioned, these calculations assume clock gating in the HWPE which is however not implemented. Still, these figures can be considered a pessimistic estimate as typical processors have IPCs beyond 1, as the HWPE was implemented in general purpose logic with nominal operation voltage, and as the CPU can spend more time in a power saving mode as the HWPE brings a significant speed-up.

\pagebreak
\section{Summary} \label{sec:summary}

During this project, an open-source AES IP core was integrated into the PULPissimo microcontroller as an hardware processing element. An FPGA demonstration showed the feasibility. Then, an ASIC design flow in a \SI{65}{nm} technology was conducted to evaluate area and power consumption.

Overall, the computation of AES encryptions can well be offloaded to hardware. The trade-off between the hardware and the software implementation is shown in \Cref{tab:conclusion}.

\begin{table}[h]
    \centering
    \begin{tabular}{c|c c}
        \toprule
        & CPU & HWPE \\
        \midrule
		Cycles four encryptions & 18300 & 97 \\
		Cycles additional encryption & 4500 & 17 \\
		Relative speed-up & 1  & 264.7 \\
		Code size [bytes] & 10052 & 9096 \\
		Area overhead [$\textrm{\micro m}^2$] & 0 & 88864 \\
		Static power [mW] & 0 & 0.4 \\
		Energy per encryption [nJ] & 46.6 & 1.1 \\
        \bottomrule
    \end{tabular}
	\caption{Comparison of computing AES CBC operations on PULPissimo's CPU and the AES HWPE.}
	\label{tab:conclusion}
\end{table}

Clearly, the HWPE brings significant speed-ups and code size reduction. However, it adds area to the chip and consumes static power even when not calculating encryption. As the HWPE drastically reduces the energy required for an AES CBC encryption, offloading to hardware pays off for a sufficiently high rate of encryptions which is \SI{1.24}{Mbps}.

\clearpage
\sloppy
\printbibliography

\end{document}
